{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906eda73-6fec-48f3-9f7c-84d5a81e7256",
   "metadata": {},
   "source": [
    "### Benchmark Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fdf74-c650-4cd0-9344-76cdba0bdd29",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.isotonic import IsotonicRegression\n\n# Import calibration methods (updated for v0.4.1)\nfrom calibre import (\n    IsotonicCalibrator,\n    NearlyIsotonicCalibrator, \n    SplineCalibrator, \n    RelaxedPAVACalibrator,\n    RegularizedIsotonicCalibrator,\n    SmoothedIsotonicCalibrator\n)\n\n# Import metrics (updated for v0.4.1)\nfrom calibre.metrics import (\n    mean_calibration_error,\n    binned_calibration_error,\n    correlation_metrics,\n    unique_value_counts\n)\n\ndef generate_nonlinear_data(n_samples=1000, noise_level=0.1):\n    \"\"\"\n    Generate synthetic data with non-linear true function and added noise.\n    \n    Parameters:\n    -----------\n    n_samples : int\n        Number of samples to generate\n    noise_level : float\n        Standard deviation of the added Gaussian noise\n    \n    Returns:\n    --------\n    x : array\n        Input features\n    y_true : array\n        True underlying function values\n    y_noisy : array\n        Noisy predictions\n    \"\"\"\n    # Generate x values\n    x = np.linspace(0, 1, n_samples)\n    \n    # Non-linear true function (e.g., a combination of sine and exponential)\n    y_true = np.sin(2 * np.pi * x) * np.exp(x - 0.5)\n    \n    # Add Gaussian noise\n    y_noisy = y_true + np.random.normal(0, noise_level, size=n_samples)\n    \n    return x, y_true, y_noisy\n\ndef benchmark_calibration_methods(noise_levels=[0.05, 0.1, 0.2]):\n    \"\"\"\n    Benchmark different calibration methods across various noise levels.\n    \n    Parameters:\n    -----------\n    noise_levels : list\n        Different noise levels to test\n    \n    Returns:\n    --------\n    results_df : pandas.DataFrame\n        Comprehensive results of calibration methods\n    \"\"\"\n    # Initialize results storage\n    results = []\n    \n    # Iterate through different noise levels\n    for noise in noise_levels:\n        # Generate data\n        x, y_true, y_noisy = generate_nonlinear_data(noise_level=noise)\n        \n        # Split data\n        x_train, x_test, y_train, y_test, y_true_train, y_true_test = train_test_split(\n            x, y_noisy, y_true, test_size=0.2, random_state=42\n        )\n        \n        # Calibration methods to test (updated for v0.4.1)\n        calibration_methods = [\n            ('Vanilla Isotonic', IsotonicCalibrator()),\n            ('Nearly Isotonic (Strict)', NearlyIsotonicCalibrator(lam=10.0)),\n            ('Nearly Isotonic (Relaxed)', NearlyIsotonicCalibrator(lam=0.1)),\n            ('I-Spline Calib', SplineCalibrator(n_splines=10, degree=3, cv=3)),\n            ('Relax PAVA (10%)', RelaxedPAVACalibrator(percentile=10)),\n            ('Regularized Isotonic', RegularizedIsotonicCalibrator(alpha=0.1)),\n            ('Smoothed Isotonic', SmoothedIsotonicCalibrator(window_length=7, poly_order=3)),\n        ]\n        \n        # Compute metrics for each method\n        for method_name, calibrator in calibration_methods:\n            try:\n                # Fit and transform using class-based API\n                calibrator.fit(x_train, y_train)\n                y_calibrated = calibrator.transform(x_train)\n                \n                # Evaluate metrics\n                mce = mean_calibration_error(y_true_train, y_calibrated)\n                bce = binned_calibration_error(y_true_train, y_calibrated, n_bins=10)\n                corr = correlation_metrics(y_true_train, y_calibrated, x=x_train, y_orig=y_train)\n                unique_counts = unique_value_counts(y_calibrated, y_orig=y_train)\n                \n                # Store results\n                results.append({\n                    'Noise Level': noise,\n                    'Method': method_name,\n                    'Mean Calibration Error': mce,\n                    'Binned Calibration Error': bce,\n                    'Spearman Corr (True)': corr['spearman_corr_to_y_true'],\n                    'Spearman Corr (Orig)': corr.get('spearman_corr_to_y_orig', np.nan),\n                    'Unique Values Ratio': unique_counts['unique_value_ratio'],\n                    'N Unique Values': unique_counts['n_unique_y_pred'],\n                    'N Unique Values (Orig)': unique_counts['n_unique_y_orig']\n                })\n            except Exception as e:\n                print(f\"Warning: {method_name} failed with error: {e}\")\n    \n    # Convert to DataFrame\n    results_df = pd.DataFrame(results)\n    return results_df\n\n# Run benchmark\nbenchmark_results = benchmark_calibration_methods()\n\n# Display results\nprint(benchmark_results)\n\n# Optional: Visualization of results\nplt.figure(figsize=(15, 10))\n\n# Metrics to plot\nmetrics_to_plot = [\n    ('Mean Calibration Error', 'Mean Calibration Error'),\n    ('Unique Values Ratio', 'Unique Values Ratio'),\n    ('Spearman Corr (True)', 'Spearman Correlation (True)')\n]\n\n# Create subplots for each metric\nfor i, (col_name, title) in enumerate(metrics_to_plot, 1):\n    plt.subplot(1, 3, i)\n    for method in benchmark_results['Method'].unique():\n        subset = benchmark_results[benchmark_results['Method'] == method]\n        plt.plot(subset['Noise Level'], subset[col_name], \n                 marker='o', label=method)\n    plt.title(title)\n    plt.xlabel('Noise Level')\n    plt.ylabel(col_name)\n    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90255d1-2db4-42a3-ba5e-1c82f32831df",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.preprocessing import StandardScaler\n\n# Import calibration methods (updated for v0.4.1)\nfrom calibre import (\n    IsotonicCalibrator,\n    NearlyIsotonicCalibrator, \n    SplineCalibrator, \n    RelaxedPAVACalibrator,\n    RegularizedIsotonicCalibrator,\n    SmoothedIsotonicCalibrator\n)\n\n# Import metrics (updated for v0.4.1)\nfrom calibre.metrics import (\n    mean_calibration_error,\n    binned_calibration_error,\n    correlation_metrics,\n    unique_value_counts\n)\n\ndef generate_continuous_data(n_samples=1000, noise_level=0.1):\n    \"\"\"\n    Generate synthetic continuous data with non-linear true function and added noise.\n    \n    Parameters:\n    -----------\n    n_samples : int\n        Number of samples to generate\n    noise_level : float\n        Standard deviation of the added Gaussian noise\n    \n    Returns:\n    --------\n    x : array\n        Input features\n    y_true : array\n        True underlying function values\n    y_noisy : array\n        Noisy predictions\n    \"\"\"\n    # Multiple non-linear functions to create complexity\n    np.random.seed(42)\n    \n    # Generate x values with more complex distribution\n    x = np.random.uniform(0, 1, n_samples)\n    \n    # Combine multiple non-linear transformations\n    y_true = (\n        np.sin(2 * np.pi * x) * np.exp(x - 0.5) +  # Sine with exponential\n        0.5 * x**2 +  # Quadratic component\n        0.3 * np.log(x + 0.1)  # Logarithmic component\n    )\n    \n    # Standardize to control overall scale\n    scaler = StandardScaler()\n    y_true = scaler.fit_transform(y_true.reshape(-1, 1)).ravel()\n    \n    # Add Gaussian noise\n    y_noisy = y_true + np.random.normal(0, noise_level, size=n_samples)\n    \n    return x, y_true, y_noisy\n\ndef benchmark_calibration_methods(noise_levels=[0.05, 0.1, 0.2]):\n    \"\"\"\n    Benchmark different calibration methods across various noise levels.\n    \n    Parameters:\n    -----------\n    noise_levels : list\n        Different noise levels to test\n    \n    Returns:\n    --------\n    results_df : pandas.DataFrame\n        Comprehensive results of calibration methods\n    \"\"\"\n    # Initialize results storage\n    results = []\n    \n    # Iterate through different noise levels\n    for noise in noise_levels:\n        # Generate data\n        x, y_true, y_noisy = generate_continuous_data(noise_level=noise)\n        \n        # Split data\n        x_train, x_test, y_train, y_test, y_true_train, y_true_test = train_test_split(\n            x, y_noisy, y_true, test_size=0.2, random_state=42\n        )\n        \n        # Calibration methods to test (updated for v0.4.1)\n        calibration_methods = [\n            ('Vanilla Isotonic', IsotonicCalibrator()),\n            ('Nearly Isotonic (Strict)', NearlyIsotonicCalibrator(lam=10.0)),\n            ('Nearly Isotonic (Relaxed)', NearlyIsotonicCalibrator(lam=0.1)),\n            ('I-Spline Calib', SplineCalibrator(n_splines=10, degree=3, cv=3)),\n            ('Relax PAVA (10%)', RelaxedPAVACalibrator(percentile=10)),\n            ('Regularized Isotonic', RegularizedIsotonicCalibrator(alpha=0.1)),\n            ('Smoothed Isotonic', SmoothedIsotonicCalibrator(window_length=7, poly_order=3)),\n        ]\n        \n        # Compute metrics for each method\n        for method_name, calibrator in calibration_methods:\n            try:\n                # Fit and transform using class-based API\n                calibrator.fit(x_train, y_train)\n                y_calibrated = calibrator.transform(x_train)\n                \n                # Evaluate metrics\n                mce = mean_calibration_error(y_true_train, y_calibrated)\n                bce = binned_calibration_error(y_true_train, y_calibrated, n_bins=10)\n                corr = correlation_metrics(y_true_train, y_calibrated, x=x_train, y_orig=y_train)\n                unique_counts = unique_value_counts(y_calibrated, y_orig=y_train)\n                \n                # Store results\n                results.append({\n                    'Noise Level': noise,\n                    'Method': method_name,\n                    'Mean Calibration Error': mce,\n                    'Binned Calibration Error': bce,\n                    'Spearman Corr (True)': corr['spearman_corr_to_y_true'],\n                    'Spearman Corr (Orig)': corr.get('spearman_corr_to_y_orig', np.nan),\n                    'Unique Values Ratio': unique_counts['unique_value_ratio'],\n                    'N Unique Values': unique_counts['n_unique_y_pred'],\n                    'N Unique Values (Orig)': unique_counts['n_unique_y_orig']\n                })\n            except Exception as e:\n                print(f\"Warning: {method_name} failed with error: {e}\")\n    \n    # Convert to DataFrame\n    results_df = pd.DataFrame(results)\n    return results_df\n\n# Run benchmark\nbenchmark_results = benchmark_calibration_methods()\n\n# Display results\nprint(benchmark_results)\n\n# Visualization\nplt.figure(figsize=(16, 5))\n\n# Metrics to plot\nmetrics_to_plot = [\n    ('Mean Calibration Error', 'Mean Calibration Error'),\n    ('Unique Values Ratio', 'Unique Values Preservation'),\n    ('Spearman Corr (True)', 'Correlation with True Values')\n]\n\n# Create subplots for each metric\nfor i, (col_name, title) in enumerate(metrics_to_plot, 1):\n    plt.subplot(1, 3, i)\n    for method in benchmark_results['Method'].unique():\n        subset = benchmark_results[benchmark_results['Method'] == method]\n        plt.plot(subset['Noise Level'], subset[col_name], \n                 marker='o', label=method)\n    plt.title(title)\n    plt.xlabel('Noise Level')\n    plt.ylabel(col_name)\n    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014c2f3-2bc3-48dd-bfc6-00cee6abe85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}