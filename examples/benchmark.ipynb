{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906eda73-6fec-48f3-9f7c-84d5a81e7256",
   "metadata": {},
   "source": [
    "### Benchmark Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fdf74-c650-4cd0-9344-76cdba0bdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import calibration methods (updated for v0.4.1)\n",
    "from calibre import (\n",
    "    IsotonicCalibrator,\n",
    "    NearlyIsotonicCalibrator,\n",
    "    RegularizedIsotonicCalibrator,\n",
    "    RelaxedPAVACalibrator,\n",
    "    SmoothedIsotonicCalibrator,\n",
    "    SplineCalibrator,\n",
    ")\n",
    "\n",
    "# Import metrics (updated for v0.4.1)\n",
    "from calibre.metrics import (\n",
    "    binned_calibration_error,\n",
    "    correlation_metrics,\n",
    "    mean_calibration_error,\n",
    "    unique_value_counts,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_nonlinear_data(n_samples=1000, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with non-linear true function and added noise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of samples to generate\n",
    "    noise_level : float\n",
    "        Standard deviation of the added Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    x : array\n",
    "        Input features\n",
    "    y_true : array\n",
    "        True underlying function values\n",
    "    y_noisy : array\n",
    "        Noisy predictions\n",
    "    \"\"\"\n",
    "    # Generate x values\n",
    "    x = np.linspace(0, 1, n_samples)\n",
    "\n",
    "    # Non-linear true function (e.g., a combination of sine and exponential)\n",
    "    y_true = np.sin(2 * np.pi * x) * np.exp(x - 0.5)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    y_noisy = y_true + np.random.normal(0, noise_level, size=n_samples)\n",
    "\n",
    "    return x, y_true, y_noisy\n",
    "\n",
    "\n",
    "def benchmark_calibration_methods(noise_levels=[0.05, 0.1, 0.2]):\n",
    "    \"\"\"\n",
    "    Benchmark different calibration methods across various noise levels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    noise_levels : list\n",
    "        Different noise levels to test\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pandas.DataFrame\n",
    "        Comprehensive results of calibration methods\n",
    "    \"\"\"\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    # Iterate through different noise levels\n",
    "    for noise in noise_levels:\n",
    "        # Generate data\n",
    "        x, y_true, y_noisy = generate_nonlinear_data(noise_level=noise)\n",
    "\n",
    "        # Split data\n",
    "        x_train, x_test, y_train, y_test, y_true_train, y_true_test = train_test_split(\n",
    "            x, y_noisy, y_true, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Calibration methods to test (updated for v0.4.1)\n",
    "        calibration_methods = [\n",
    "            (\"Vanilla Isotonic\", IsotonicCalibrator()),\n",
    "            (\"Nearly Isotonic (Strict)\", NearlyIsotonicCalibrator(lam=10.0)),\n",
    "            (\"Nearly Isotonic (Relaxed)\", NearlyIsotonicCalibrator(lam=0.1)),\n",
    "            (\"I-Spline Calib\", SplineCalibrator(n_splines=10, degree=3, cv=3)),\n",
    "            (\"Relax PAVA (10%)\", RelaxedPAVACalibrator(percentile=10)),\n",
    "            (\"Regularized Isotonic\", RegularizedIsotonicCalibrator(alpha=0.1)),\n",
    "            (\n",
    "                \"Smoothed Isotonic\",\n",
    "                SmoothedIsotonicCalibrator(window_length=7, poly_order=3),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Compute metrics for each method\n",
    "        for method_name, calibrator in calibration_methods:\n",
    "            try:\n",
    "                # Fit and transform using class-based API\n",
    "                calibrator.fit(x_train, y_train)\n",
    "                y_calibrated = calibrator.transform(x_train)\n",
    "\n",
    "                # Evaluate metrics\n",
    "                mce = mean_calibration_error(y_true_train, y_calibrated)\n",
    "                bce = binned_calibration_error(y_true_train, y_calibrated, n_bins=10)\n",
    "                corr = correlation_metrics(\n",
    "                    y_true_train, y_calibrated, x=x_train, y_orig=y_train\n",
    "                )\n",
    "                unique_counts = unique_value_counts(y_calibrated, y_orig=y_train)\n",
    "\n",
    "                # Store results\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"Noise Level\": noise,\n",
    "                        \"Method\": method_name,\n",
    "                        \"Mean Calibration Error\": mce,\n",
    "                        \"Binned Calibration Error\": bce,\n",
    "                        \"Spearman Corr (True)\": corr[\"spearman_corr_to_y_true\"],\n",
    "                        \"Spearman Corr (Orig)\": corr.get(\n",
    "                            \"spearman_corr_to_y_orig\", np.nan\n",
    "                        ),\n",
    "                        \"Unique Values Ratio\": unique_counts[\"unique_value_ratio\"],\n",
    "                        \"N Unique Values\": unique_counts[\"n_unique_y_pred\"],\n",
    "                        \"N Unique Values (Orig)\": unique_counts[\"n_unique_y_orig\"],\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: {method_name} failed with error: {e}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_results = benchmark_calibration_methods()\n",
    "\n",
    "# Display results\n",
    "print(benchmark_results)\n",
    "\n",
    "# Optional: Visualization of results\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Metrics to plot\n",
    "metrics_to_plot = [\n",
    "    (\"Mean Calibration Error\", \"Mean Calibration Error\"),\n",
    "    (\"Unique Values Ratio\", \"Unique Values Ratio\"),\n",
    "    (\"Spearman Corr (True)\", \"Spearman Correlation (True)\"),\n",
    "]\n",
    "\n",
    "# Create subplots for each metric\n",
    "for i, (col_name, title) in enumerate(metrics_to_plot, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    for method in benchmark_results[\"Method\"].unique():\n",
    "        subset = benchmark_results[benchmark_results[\"Method\"] == method]\n",
    "        plt.plot(subset[\"Noise Level\"], subset[col_name], marker=\"o\", label=method)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Noise Level\")\n",
    "    plt.ylabel(col_name)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90255d1-2db4-42a3-ba5e-1c82f32831df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import calibration methods (updated for v0.4.1)\n",
    "\n",
    "# Import metrics (updated for v0.4.1)\n",
    "\n",
    "\n",
    "def generate_continuous_data(n_samples=1000, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic continuous data with non-linear true function and added noise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of samples to generate\n",
    "    noise_level : float\n",
    "        Standard deviation of the added Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    x : array\n",
    "        Input features\n",
    "    y_true : array\n",
    "        True underlying function values\n",
    "    y_noisy : array\n",
    "        Noisy predictions\n",
    "    \"\"\"\n",
    "    # Multiple non-linear functions to create complexity\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Generate x values with more complex distribution\n",
    "    x = np.random.uniform(0, 1, n_samples)\n",
    "\n",
    "    # Combine multiple non-linear transformations\n",
    "    y_true = (\n",
    "        np.sin(2 * np.pi * x) * np.exp(x - 0.5)  # Sine with exponential\n",
    "        + 0.5 * x**2  # Quadratic component\n",
    "        + 0.3 * np.log(x + 0.1)  # Logarithmic component\n",
    "    )\n",
    "\n",
    "    # Standardize to control overall scale\n",
    "    scaler = StandardScaler()\n",
    "    y_true = scaler.fit_transform(y_true.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    y_noisy = y_true + np.random.normal(0, noise_level, size=n_samples)\n",
    "\n",
    "    return x, y_true, y_noisy\n",
    "\n",
    "\n",
    "def benchmark_calibration_methods(noise_levels=[0.05, 0.1, 0.2]):\n",
    "    \"\"\"\n",
    "    Benchmark different calibration methods across various noise levels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    noise_levels : list\n",
    "        Different noise levels to test\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pandas.DataFrame\n",
    "        Comprehensive results of calibration methods\n",
    "    \"\"\"\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    # Iterate through different noise levels\n",
    "    for noise in noise_levels:\n",
    "        # Generate data\n",
    "        x, y_true, y_noisy = generate_continuous_data(noise_level=noise)\n",
    "\n",
    "        # Split data\n",
    "        x_train, x_test, y_train, y_test, y_true_train, y_true_test = train_test_split(\n",
    "            x, y_noisy, y_true, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Calibration methods to test (updated for v0.4.1)\n",
    "        calibration_methods = [\n",
    "            (\"Vanilla Isotonic\", IsotonicCalibrator()),\n",
    "            (\"Nearly Isotonic (Strict)\", NearlyIsotonicCalibrator(lam=10.0)),\n",
    "            (\"Nearly Isotonic (Relaxed)\", NearlyIsotonicCalibrator(lam=0.1)),\n",
    "            (\"I-Spline Calib\", SplineCalibrator(n_splines=10, degree=3, cv=3)),\n",
    "            (\"Relax PAVA (10%)\", RelaxedPAVACalibrator(percentile=10)),\n",
    "            (\"Regularized Isotonic\", RegularizedIsotonicCalibrator(alpha=0.1)),\n",
    "            (\n",
    "                \"Smoothed Isotonic\",\n",
    "                SmoothedIsotonicCalibrator(window_length=7, poly_order=3),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Compute metrics for each method\n",
    "        for method_name, calibrator in calibration_methods:\n",
    "            try:\n",
    "                # Fit and transform using class-based API\n",
    "                calibrator.fit(x_train, y_train)\n",
    "                y_calibrated = calibrator.transform(x_train)\n",
    "\n",
    "                # Evaluate metrics\n",
    "                mce = mean_calibration_error(y_true_train, y_calibrated)\n",
    "                bce = binned_calibration_error(y_true_train, y_calibrated, n_bins=10)\n",
    "                corr = correlation_metrics(\n",
    "                    y_true_train, y_calibrated, x=x_train, y_orig=y_train\n",
    "                )\n",
    "                unique_counts = unique_value_counts(y_calibrated, y_orig=y_train)\n",
    "\n",
    "                # Store results\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"Noise Level\": noise,\n",
    "                        \"Method\": method_name,\n",
    "                        \"Mean Calibration Error\": mce,\n",
    "                        \"Binned Calibration Error\": bce,\n",
    "                        \"Spearman Corr (True)\": corr[\"spearman_corr_to_y_true\"],\n",
    "                        \"Spearman Corr (Orig)\": corr.get(\n",
    "                            \"spearman_corr_to_y_orig\", np.nan\n",
    "                        ),\n",
    "                        \"Unique Values Ratio\": unique_counts[\"unique_value_ratio\"],\n",
    "                        \"N Unique Values\": unique_counts[\"n_unique_y_pred\"],\n",
    "                        \"N Unique Values (Orig)\": unique_counts[\"n_unique_y_orig\"],\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: {method_name} failed with error: {e}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_results = benchmark_calibration_methods()\n",
    "\n",
    "# Display results\n",
    "print(benchmark_results)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "# Metrics to plot\n",
    "metrics_to_plot = [\n",
    "    (\"Mean Calibration Error\", \"Mean Calibration Error\"),\n",
    "    (\"Unique Values Ratio\", \"Unique Values Preservation\"),\n",
    "    (\"Spearman Corr (True)\", \"Correlation with True Values\"),\n",
    "]\n",
    "\n",
    "# Create subplots for each metric\n",
    "for i, (col_name, title) in enumerate(metrics_to_plot, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    for method in benchmark_results[\"Method\"].unique():\n",
    "        subset = benchmark_results[benchmark_results[\"Method\"] == method]\n",
    "        plt.plot(subset[\"Noise Level\"], subset[col_name], marker=\"o\", label=method)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Noise Level\")\n",
    "    plt.ylabel(col_name)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014c2f3-2bc3-48dd-bfc6-00cee6abe85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}